{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d7f96",
   "metadata": {},
   "outputs": [],
   "source": "# Mini-project 5.3 Detecting the anomalous activity of a ship's engine\n\n**Welcome to your first mini-project: Detecting the anomalous activity of a ship's engine!**\n\nThis mini-project allows you to dive deep into a real-world challenge, applying and honing the data science skills you've been cultivating so far. In this immersive exploration into detecting the anomalous activity of a ship's engine, you can practically apply the concepts you've learned over the past few weeks.\n\nA poorly maintained ship engine in the supply chain industry can lead to inefficiencies, increased fuel consumption, higher risks of malfunctions, and potential safety hazards. Your challenge in this project is to apply critical thinking and ML concepts to design and implement a robust anomaly detection model.\n\nPlease set aside approximately **12 hours** to complete the mini-project.\n\n<br></br>\n\n## **Business context**\nYou are provided with a real data set to identify anomalous activity in a ship's engine functionality (Devabrat,  2022). As you work through this project, keep in mind that, typically speaking, anomalies would make up a minority of the data points (i.e., about 1% to 5% of the data points would be anomalies).\n\nThe data set contains six important features continuously monitored to evaluate the engine's status as 'good' or 'bad'. These features are:\n- **Engine rpm (revolutions per minute):**\n\nA high rpm indicates the engine is operating at a higher speed than designed for prolonged periods, which can lead to overheating, excessive wear, and eventual failure.\n\nA low rpm could signal a lack of power, issues with fuel delivery, or internal mechanical problems.\n\n- **Lubrication oil pressure:**\n\nLow lubrication oil pressure indicates insufficient lubrication, leading to increased friction, overheating, and engine damage.\n\nA high lubrication oil pressure could signal a blockage in the oil delivery system, potentially causing seal or gasket failure.\n\n- **Fuel pressure:**\n\nHigh fuel pressure can cause poor engine performance and incomplete combustion, indicating fuel pump or filter issues.\n\nA low fuel pressure may result in excessive fuel consumption, poor emissions, or damage to the fuel injectors.\n\n- **Coolant pressure:**\n\nLow coolant pressure indicates a potential leak in the cooling system or a coolant pump failure, risking engine overheating.\n\nA high coolant pressure could be a sign of a blockage in the cooling system or a failing head gasket, which can also lead to overheating.\n\n- **Lubrication oil temperature:**\n\nHigh lubrication oil temperature suggests the oil is overheating, which can degrade its lubricating properties and lead to engine damage.\n\nA low lubrication oil temperature may indicate it is not reaching its optimal operating temperature, potentially causing inadequate lubrication.\n\n- **Coolant temperature:**\n\nHigh coolant temperature signals overheating, which various issues, including a failed thermostat, coolant leak, or insufficient coolant flow can cause.\n\nA low coolant temperature could suggest the engine is not reaching its optimal operating temperature, affecting performance and efficiency.\n\nIssues with engines could lead to engine malfunctions, potential safety hazards, and downtime (e.g. delayed deliveries), resulting in the breakdown of a ship's overall functionality, consequently impacting the business, such as affecting revenue via failure to deliver goods. By predicting timely maintenance, the business aims to increase profit by reducing downtime, reducing safety risks for the crew, limiting fuel consumption, and increasing customer satisfaction through timely deliveries.\n\nYour task is to develop a robust anomaly detection system to protect a company's shipping fleet by evaluating engine functionality. Therefore, you'll explore the data and:\n- employ preprocessing and feature engineering\n- perform anomaly detection.\n\nYou must prepare a report illustrating your insights to the prospective stakeholders, explaining your approach in identifying anomalies, presenting your findings and including recommendations.\n\n<br></br>\n\n> **Disclaimer**\n>\n> Please note that although a real-life data set was provided, the business context in this project is fictitious. Any resemblance to companies and persons (living or dead) is coincidental. The course designers and hosts assume no responsibility or liability for any errors or omissions in the content of the business context and data sets. The information in the data sets is provided on an 'as is' basis with no guarantees of completeness, accuracy, usefulness, or timeliness.\n\n<br></br>\n\n## **Objective**\nBy the end of this mini-project, you will be able to understand and apply statistical and ML methods for detecting anomalies.\n\nIn the Notebook, you will:\n- explore the data set\n- preprocess the data and conduct feature engineering\n- apply statistical techniques to detect anomalies\n- use ML algorithms to detect anomalies.\n\nYou will also write a report summarising the results of your findings and recommendations.\n\n<br></br>\n\n## **Assessment criteria**\nBy completing this project, you will be able to provide evidence that you can:\n- demonstrate enhanced problem-solving skills and proposed strategic solutions by systematically analysing complex organisational challenges\n- identify meaningful patterns in complex data to evidence advanced critical and statistical thinking skills\n- select statistical techniques appropriate to a solutions design approach and evidence the ability to evaluate their effectiveness\n- demonstrate enhanced data representation and improved model performance by systematically implementing relevant techniques\n- design innovative solutions through critically selecting, evaluating and implementing effective unsupervised learning techniques.\n\n<br></br>\n\n## **Project guidance**\n1. Import the required libraries and data set with the provided URL.\n2. View the DataFrame and perform EDA, including identifying missing or duplicate values.\n3. Generate the descriptive statistics of the data, including:\n - observing the mean for each feature\n - identifying the median\n4. Visualise the data to determine the distribution and extreme values.\n5. Perform anomaly detection with a statistical method and identify possible anomalies. Specifically:\n  - Use the interquartile range (IQR) method to identify outliers for each feature.\n  - Create a new column (corresponding to each feature) that will indicate (in binary â€“ 0,1) if the value of that feature is an outlier as per IQR calculations.\n  - Use IQR to identify the number of features that must simultaneously be in outlier condition, in order for a sample to be classified as an outlier, such that the total percentage of samples identified as outliers falls within the 1-5% range.\n  - Record your thoughts and observations.\n6. Perform anomaly detection with ML models:\n  - Using one-class SVM,\n    - identify possible anomalies\n    - visualise the output in 2D after performing PCA and ensure the outliers are in a different colour\n    - apply different combinations of parameter settings to improve the model's outlier predictions to the expected 1-5%\n    - record your insights about the use of this method.\n  - Using Isolation Forest,\n    - identify possible anomalies\n    - visualise the output in 2D after performing PCA and ensure the outliers are in a different colour\n    - apply different combinations of parameter settings to improve the model's outlier predictions to the expected 1-5%\n    - record your insights about the use of this method.\n7. Document your approach and major inferences from the data analysis and describe which method (and parameters) provided the best results and why.\n8. When you've completed the activity:\n  - Download your completed Notebook as an IPYNB (Jupyter Notebook). Save the file as follows: LastName_FirstName_CAM_C101_W5_Mini-project.ipynb\n  - Prepare a detailed report (between 800-1000 words) that includes:\n    - an overview of the problem that is being addressed in this project\n    - an overview of your approach, with a clear visualisation of your anomaly detection approach\n    - key figures and tables of the main results\n    - interpretation of the anomaly detection results\n    - an evaluation of the effectiveness of 2D PCA plots in highlighting outliers\n    - recommendations based on gathered evidence.\n  - Save the document as a PDF named according to the following convention: LastName_FirstName_CAM_C101_W5_Mini-project.pdf.\n\n\n<br></br>\n> **Declaration**\n>\n> By submitting your project, you indicate that the work is your own and has been created with academic integrity. Refer to the Cambridge plagiarism regulations.\n> Start your activity here. Select the pen from the toolbar to add your entry.\nurl = 'https://raw.githubusercontent.com/fourthrevlxd/cam_dsb/main/engine.csv'\nimport pandas as pd\ndf = pd.read_csv(url)\nprint(\"DataFrame Head:\")\nprint(df.head())\n\nprint(\"\\nDataFrame Info:\")\ndf.info()\n\nprint(\"\\nDescriptive Statistics:\")\nprint(df.describe())\n\nprint(\"\\nNull Values:\")\nprint(df.isnull().sum())\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Get the list of feature columns\nfeatures = df.columns\n\n# Determine the number of rows and columns for the subplot grid\nnum_features = len(features)\nnum_cols = 2  # You can adjust this for desired layout\nnum_rows = (num_features + num_cols - 1) // num_cols\n\nplt.figure(figsize=(15, num_rows * 5))\n\nfor i, feature in enumerate(features):\n    plt.subplot(num_rows, num_cols, i + 1)\n    sns.scatterplot(x=df.index, y=df[feature])\n    plt.title(f'Scatter Plot of {feature}')\n    plt.xlabel('Data Point Index')\n    plt.ylabel(feature)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"These scatter plots show each feature's values across the dataset's index. Extreme values will appear as points far from the main cluster. For a more direct view of distribution and quartiles, box plots and histograms can also be very insightful.\")\n# Clean the data: Remove extreme outliers in Coolant temp\ndf_cleaned = df.copy()\ndf_cleaned = df_cleaned[df_cleaned['Coolant temp'] <= 100]\n\n# Store total samples for later use\ntotal_samples = len(df_cleaned)\n\nprint(\"Descriptive Statistics for 'Coolant temp' after removing values > 100:\")\nprint(df_cleaned['Coolant temp'].describe())\n\nprint(f\"\\nOriginal DataFrame shape: {df.shape}\")\nprint(f\"Cleaned DataFrame shape: {df_cleaned.shape}\")\nprint(f\"\\nTotal samples stored in variable: {total_samples}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cy3yg9c8ov",
   "source": "# =============================================================================\n# PHASE 1: OPERATING MODE DISCOVERY\n# =============================================================================\n\n## Investigation: Are the bimodal distributions caused by two distinct operating modes?\n\nBased on the histograms, several features show bimodal distributions (two bumps). \nI hypothesize that **Engine rpm** is the driving variable creating two distinct operating modes.\n\n**Approach:** \n- Explore the Engine rpm distribution\n- Split data into LOW and HIGH operating modes\n- Verify that this split explains the bimodal patterns in other features",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "liwlm9mii5",
   "source": "# =============================================================================\n# STEP 1.1: Explore Engine RPM distribution\n# =============================================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Histogram with KDE\nplt.figure(figsize=(12, 6))\nsns.histplot(df_cleaned['Engine rpm'], kde=True, bins=50, color='steelblue', edgecolor='black')\nplt.title('Distribution of Engine RPM', fontsize=14, fontweight='bold')\nplt.xlabel('Engine RPM', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.axvline(df_cleaned['Engine rpm'].median(), color='red', linestyle='--', linewidth=2, label=f'Median: {df_cleaned[\"Engine rpm\"].median():.2f}')\nplt.axvline(df_cleaned['Engine rpm'].mean(), color='orange', linestyle='--', linewidth=2, label=f'Mean: {df_cleaned[\"Engine rpm\"].mean():.2f}')\nplt.legend()\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Print descriptive statistics\nprint(\"=\"*80)\nprint(\"ENGINE RPM - DESCRIPTIVE STATISTICS\")\nprint(\"=\"*80)\nprint(df_cleaned['Engine rpm'].describe())\nprint(\"\\nAdditional Statistics:\")\nprint(f\"Variance: {df_cleaned['Engine rpm'].var():.2f}\")\nprint(f\"Skewness: {df_cleaned['Engine rpm'].skew():.2f}\")\nprint(f\"Kurtosis: {df_cleaned['Engine rpm'].kurtosis():.2f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUAL INSPECTION GUIDE\")\nprint(\"=\"*80)\nprint(\"Look at the histogram above:\")\nprint(\"  - Do you see TWO distinct peaks (bumps)?\")\nprint(\"  - Is there a 'valley' between them?\")\nprint(\"  - Where would you draw a line to separate LOW mode from HIGH mode?\")\nprint(\"\\nSuggested threshold: Use the MEDIAN as the split point (red line)\")\nprint(f\"Median RPM: {df_cleaned['Engine rpm'].median():.2f}\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ptulcc1slh9",
   "source": "# =============================================================================\n# STEP 1.2: Create operating_mode column\n# =============================================================================\n\n# Use median as threshold to split into LOW and HIGH modes\nrpm_threshold = df_cleaned['Engine rpm'].median()\n\n# Create operating_mode column\ndf_cleaned['operating_mode'] = df_cleaned['Engine rpm'].apply(\n    lambda x: 'LOW' if x <= rpm_threshold else 'HIGH'\n)\n\n# Print summary statistics\nprint(\"=\"*80)\nprint(\"OPERATING MODE SPLIT SUMMARY\")\nprint(\"=\"*80)\nprint(f\"Threshold used: {rpm_threshold:.2f} RPM (median)\\n\")\n\nmode_counts = df_cleaned['operating_mode'].value_counts()\nprint(f\"{'Mode':<10} {'Count':>10} {'Percentage':>12}\")\nprint(\"-\"*80)\nfor mode, count in mode_counts.items():\n    pct = (count / total_samples) * 100\n    print(f\"{mode:<10} {count:>10} {pct:>11.2f}%\")\nprint(\"=\"*80)\n\n# Visualize Engine RPM colored by operating mode\nplt.figure(figsize=(12, 6))\n\n# Plot LOW mode\nlow_data = df_cleaned[df_cleaned['operating_mode'] == 'LOW']['Engine rpm']\nhigh_data = df_cleaned[df_cleaned['operating_mode'] == 'HIGH']['Engine rpm']\n\nplt.hist(low_data, bins=30, alpha=0.6, color='blue', label='LOW Mode', edgecolor='black')\nplt.hist(high_data, bins=30, alpha=0.6, color='red', label='HIGH Mode', edgecolor='black')\n\nplt.axvline(rpm_threshold, color='green', linestyle='--', linewidth=3, label=f'Threshold: {rpm_threshold:.2f}')\nplt.title('Engine RPM Distribution by Operating Mode', fontsize=14, fontweight='bold')\nplt.xlabel('Engine RPM', fontsize=12)\nplt.ylabel('Frequency', fontsize=12)\nplt.legend(fontsize=11)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\">>> CHECKPOINT 1: STOP HERE\")\nprint(\"=\"*80)\nprint(\"Please verify:\")\nprint(\"  1. Does the split look reasonable?\")\nprint(\"  2. Are the two modes roughly balanced?\")\nprint(\"  3. Should we use the median, or suggest a different threshold?\")\nprint(\"\\nPlease confirm before I continue to Phase 2.\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}